# ISO/IEC 42001:2023 - Sistema de Gestión de Inteligencia Artificial (AIMS)

## Visión General

ISO/IEC 42001:2023 es el primer estándar internacional para **Sistemas de Gestión de Inteligencia Artificial (AIMS - Artificial Intelligence Management Systems)**. Publicado en diciembre de 2023, proporciona un marco estructurado para la gobernanza de IA.

### Datos Clave
- **Código:** ISO/IEC 42001:2023
- **Título:** Information Technology – Artificial Intelligence – Management Systems
- **Publicación:** Diciembre 2023
- **Aplicabilidad:** Organizaciones de cualquier tamaño que desarrollan, proveen o usan sistemas de IA

## Propósito y Alcance

### Objetivo
Proporcionar requisitos para establecer, implementar, mantener y mejorar continuamente un Sistema de Gestión de Inteligencia Artificial (AIMS).

### Cobertura
- Gestión de riesgos para sistemas de IA
- Evaluaciones de impacto antes de implementación
- Gestión del ciclo de vida de sistemas
- Supervisión de proveedores terceros
- Prácticas de gobernanza de datos
- Uso ético y responsable de IA

### Aplicabilidad
El estándar es aplicable a:
- Desarrolladores de sistemas de IA
- Proveedores de productos/servicios de IA
- Usuarios/operadores de sistemas de IA
- Cualquier industria (financiero, salud, manufactura, etc.)
- Sector público y privado

## Estructura del Estándar

### Cláusulas 1-3: Contexto y Definiciones
- Alcance del estándar
- Referencias normativas
- Términos y definiciones

### Cláusula 4: Contexto de la Organización
Requisitos para:
- Identificar factores internos y externos que influyen en el AIMS
- Definir el alcance del AIMS
- Identificar riesgos relacionados con IA
- Comprender expectativas de clientes y stakeholders

### Cláusula 5: Liderazgo
Requisitos para alta dirección:
- Establecer política de IA
- Asignar responsabilidad para toma de decisiones sobre IA
- Integrar gobernanza de IA en estrategia de negocio
- Demostrar compromiso con el AIMS

### Cláusula 6: Planificación
Requisitos para:
- Identificar y evaluar riesgos de IA
- Definir objetivos de IA
- Planificar acciones para abordar riesgos y oportunidades
- Gestionar cambios en el AIMS

### Cláusula 7: Soporte
Requisitos de recursos:
- Competencia del personal
- Awareness sobre IA
- Comunicación interna y externa
- Información documentada

### Cláusula 8: Operación
Requisitos operativos:
- Implementar controles para mitigar riesgos (8.2)
- Planificación y control operacional
- Gestión de cambios
- Control de productos/servicios externos

### Cláusula 9: Evaluación del Desempeño
Requisitos de monitoreo:
- Monitoreo, medición, análisis y evaluación
- Auditoría interna
- Revisión por la dirección

### Cláusula 10: Mejora
Requisitos de mejora continua:
- Identificar y abordar no conformidades
- Implementar acciones correctivas
- Adaptar políticas a nuevos riesgos o avances tecnológicos
- Mejora continua del AIMS

## Anexo A: Controles de Referencia (Detalle Oficial)

El Anexo A proporciona controles de referencia para abordar riesgos de IA. No todos los controles son obligatorios; la organización selecciona los aplicables según su contexto y documenta justificación en el Statement of Applicability.

### A.2 Políticas Relacionadas con IA
**Objetivo:** Proporcionar dirección y apoyo de gestión para sistemas de IA según requisitos del negocio.

| Control | Descripción |
|---------|-------------|
| **A.2.2** Política de IA | Documentar política para desarrollo o uso de sistemas de IA |
| **A.2.3** Alineación con otras políticas | Determinar dónde otras políticas aplican a objetivos de IA |
| **A.2.4** Revisión de política | Revisar política en intervalos planificados |

### A.3 Organización Interna
**Objetivo:** Establecer accountability para implementación, operación y gestión responsable de sistemas de IA.

| Control | Descripción |
|---------|-------------|
| **A.3.2** Roles y responsabilidades | Definir y asignar roles según necesidades de la organización |
| **A.3.3** Reporte de preocupaciones | Proceso para reportar preocupaciones durante ciclo de vida |

### A.4 Recursos para Sistemas de IA
**Objetivo:** Asegurar que la organización gestiona recursos (componentes y activos) para entender y abordar riesgos e impactos.

| Control | Descripción |
|---------|-------------|
| **A.4.2** Documentación de recursos | Identificar y documentar recursos para cada etapa del ciclo de vida |
| **A.4.3** Recursos de datos | Documentar información sobre recursos de datos utilizados |
| **A.4.4** Recursos de herramientas | Documentar herramientas (algoritmos, modelos, tools) |
| **A.4.5** Recursos de sistema y cómputo | Documentar recursos de hardware y cómputo |
| **A.4.6** Recursos humanos | Documentar competencias requeridas para desarrollo, operación, mantenimiento |

### A.5 Evaluación de Impactos de Sistemas de IA
**Objetivo:** Evaluar impactos a individuos, grupos y sociedades afectados por el sistema de IA.

| Control | Descripción |
|---------|-------------|
| **A.5.2** Proceso de evaluación de impacto | Establecer proceso para evaluar consecuencias potenciales |
| **A.5.3** Documentación de evaluaciones | Documentar y retener resultados por período definido |
| **A.5.4** Impacto en individuos/grupos | Evaluar y documentar impactos potenciales en personas |
| **A.5.5** Impactos sociales | Evaluar y documentar impactos sociales potenciales |

### A.6 Ciclo de Vida del Sistema de IA

#### A.6.1 Guía de Gestión para Desarrollo
**Objetivo:** Asegurar que la organización identifica objetivos y procesos para diseño y desarrollo responsable.

| Control | Descripción |
|---------|-------------|
| **A.6.1.2** Objetivos para desarrollo responsable | Identificar y documentar objetivos que guían desarrollo responsable |
| **A.6.1.3** Procesos para diseño responsable | Definir y documentar procesos específicos para diseño y desarrollo |

#### A.6.2 Ciclo de Vida del Sistema
**Objetivo:** Definir criterios y requisitos para cada etapa del ciclo de vida.

| Control | Descripción |
|---------|-------------|
| **A.6.2.2** Requisitos y especificación | Especificar y documentar requisitos para sistemas nuevos o mejoras |
| **A.6.2.3** Documentación de diseño | Documentar diseño basado en objetivos y criterios |
| **A.6.2.4** Verificación y validación | Definir medidas de V&V y criterios de uso |
| **A.6.2.5** Despliegue | Documentar plan de deployment y requisitos previos |
| **A.6.2.6** Operación y monitoreo | Definir elementos para operación continua (monitoreo, updates, soporte) |
| **A.6.2.7** Documentación técnica | Determinar documentación necesaria para cada categoría de interesados |
| **A.6.2.8** Registro de logs de eventos | Determinar en qué fases habilitar logging (mínimo: cuando está en uso) |

### A.7 Datos para Sistemas de IA
**Objetivo:** Asegurar que la organización entiende el rol e impactos de datos en sistemas de IA.

| Control | Descripción |
|---------|-------------|
| **A.7.2** Datos para desarrollo | Definir e implementar procesos de gestión de datos para desarrollo |
| **A.7.3** Adquisición de datos | Determinar y documentar detalles de adquisición y selección |
| **A.7.4** Calidad de datos | Definir requisitos de calidad y asegurar cumplimiento |
| **A.7.5** Proveniencia de datos | Definir proceso para registrar proveniencia durante ciclo de vida |
| **A.7.6** Preparación de datos | Definir criterios y métodos de preparación de datos |

### A.8 Información para Partes Interesadas
**Objetivo:** Asegurar que partes interesadas tienen información necesaria para entender riesgos e impactos.

| Control | Descripción |
|---------|-------------|
| **A.8.2** Documentación e información para usuarios | Determinar y proporcionar información necesaria a usuarios |
| **A.8.3** Reporte externo | Proporcionar capacidades para reportar impactos adversos |
| **A.8.4** Comunicación de incidentes | Determinar y documentar plan de comunicación de incidentes |
| **A.8.5** Información para interesados | Documentar obligaciones de reporte a partes interesadas |

### A.9 Uso de Sistemas de IA
**Objetivo:** Asegurar que la organización usa sistemas de IA responsablemente según políticas.

| Control | Descripción |
|---------|-------------|
| **A.9.2** Procesos para uso responsable | Definir y documentar procesos para uso responsable |
| **A.9.3** Objetivos para uso responsable | Identificar y documentar objetivos que guían uso responsable |
| **A.9.4** Uso previsto del sistema | Asegurar uso según propósito previsto y documentación |

### A.10 Relaciones con Terceros y Clientes
**Objetivo:** Asegurar que la organización entiende responsabilidades y mantiene accountability cuando terceros intervienen.

| Control | Descripción |
|---------|-------------|
| **A.10.2** Asignación de responsabilidades | Asignar responsabilidades entre organización, partners, proveedores, clientes |
| **A.10.3** Proveedores | Establecer proceso para alinear uso de proveedores con enfoque responsable |
| **A.10.4** Clientes | Asegurar que enfoque responsable considera expectativas de clientes |

## Anexo C: Objetivos Organizacionales y Fuentes de Riesgo

### Objetivos Potenciales para Gestión de IA
| Objetivo | Descripción |
|----------|-------------|
| **Accountability** | Mantener marcos de rendición de cuentas con uso de IA |
| **Expertise en IA** | Contar con especialistas interdisciplinarios |
| **Disponibilidad de datos** | Asegurar datos de training y test de calidad |
| **Impacto ambiental** | Considerar impactos positivos y negativos al ambiente |
| **Fairness** | Evitar aplicaciones injustas para personas o grupos |
| **Mantenibilidad** | Capacidad de modificar sistema para corregir defectos |
| **Privacidad** | Proteger datos personales y sensibles |
| **Robustez** | Performance comparable en datos nuevos vs. entrenamiento |
| **Seguridad (Safety)** | Sistema no pone en peligro vida, salud, propiedad o ambiente |
| **Seguridad (Security)** | Protección contra amenazas específicas de ML |
| **Transparencia y explicabilidad** | Información comprensible sobre factores que influyen resultados |

### Fuentes de Riesgo
- **Complejidad del entorno:** Amplio rango de situaciones afecta performance
- **Falta de transparencia:** Incapacidad de proporcionar información adecuada
- **Nivel de automatización:** Impacto en safety, fairness, security
- **Riesgos de ML:** Calidad de datos, data poisoning, sesgos
- **Hardware:** Errores de componentes, transferencia entre sistemas
- **Ciclo de vida:** Fallas en diseño, deployment inadecuado, falta de mantenimiento
- **Madurez tecnológica:** Factores desconocidos o complacencia tecnológica

## Anexo B: Guía de Implementación (Resumen)

El Anexo B proporciona guía normativa para implementar los controles del Anexo A.

### B.5 Evaluación de Impacto - Consideraciones Clave

**Cuándo realizar evaluación de impacto:**
- Criticidad del propósito y contexto de uso
- Complejidad de la tecnología de IA y nivel de automatización
- Sensibilidad de tipos de datos procesados

**Elementos del proceso:**
1. Identificación (fuentes, eventos, resultados)
2. Análisis (consecuencias y probabilidad)
3. Evaluación (decisiones de aceptación, priorización)
4. Tratamiento (medidas de mitigación)
5. Documentación, reporte y comunicación

**Áreas de impacto a evaluar:**
- Fairness (equidad)
- Accountability (rendición de cuentas)
- Transparencia y explicabilidad
- Seguridad y privacidad
- Seguridad física y salud
- Consecuencias financieras
- Accesibilidad
- Derechos humanos

### B.6 Ciclo de Vida - Consideraciones de Desarrollo

**Procesos de desarrollo responsable deben incluir:**
- Etapas del ciclo de vida definidas
- Requisitos y medios de testing
- Requisitos de supervisión humana
- Etapas para evaluaciones de impacto
- Expectativas y reglas de datos de training
- Expertise requerido o training para desarrolladores
- Criterios de release
- Aprobaciones necesarias en cada etapa
- Control de cambios
- Usabilidad y controlabilidad
- Engagement de partes interesadas

**Documentación técnica debe incluir:**
- Descripción general y propósito
- Instrucciones de uso
- Supuestos técnicos (ambiente, software, hardware, datos)
- Limitaciones técnicas (tasas de error, precisión, robustez)
- Capacidades de monitoreo y funciones de control

### B.7 Datos - Consideraciones de Gestión

**Temas de gestión de datos:**
- Implicaciones de privacidad y seguridad
- Amenazas de safety/security por datos
- Transparencia y explicabilidad (proveniencia, explicación de uso)
- Representatividad de datos de training vs. dominio operacional
- Exactitud e integridad de datos

**Documentación de adquisición de datos:**
- Categorías de datos necesarios
- Cantidad de datos requerida
- Fuentes (internas, compradas, compartidas, abiertas, sintéticas)
- Características de la fuente (estática, streaming, generada)
- Demografía y características de sujetos de datos
- Manejo previo de datos (usos anteriores, cumplimiento)
- Derechos de datos (PII, copyright)
- Metadata asociada (etiquetado, enriquecimiento)
- Proveniencia de datos

### B.9 Uso Responsable - Objetivos

**Objetivos para uso responsable pueden incluir:**
- Fairness
- Accountability
- Transparencia
- Explicabilidad
- Confiabilidad
- Seguridad (Safety)
- Robustez y redundancia
- Privacidad y seguridad
- Accesibilidad

**Supervisión humana debe considerar:**
- Revisores humanos para verificar outputs
- Autoridad para override de decisiones del sistema
- Monitoreo de performance y precisión
- Reporte de preocupaciones sobre outputs e impactos
- Reporte de cambios en performance
- Evaluación de si decisiones automatizadas son apropiadas

## Anexo D: Integración con Otros Estándares (Oficial)

### Estándares de Gestión Complementarios

| Estándar | Integración con ISO 42001 |
|----------|---------------------------|
| **ISO/IEC 27001** | Seguridad es clave para objetivos de IA. Estructura armonizada facilita integración. Controles de seguridad de ISO 42001 se integran con ISMS. |
| **ISO/IEC 27701** | Cuando se procesa PII, privacidad debe cumplirse. Objetivos y controles de privacidad se integran con PIMS. |
| **ISO 9001** | Certificación conjunta refuerza confianza del cliente. Complementa requisitos de gestión de riesgos, desarrollo de software, cadena de suministro. |
| **ISO 22000** | Relevante para IA en producción alimentaria, preparación y logística. |
| **ISO 13485** | Soporta requisitos de software de dispositivos médicos. |
| **IEC 62304** | Requisitos de ciclo de vida de software médico. |

### Sectores de Aplicación
El AIMS es aplicable a cualquier organización en sectores como:
- Salud
- Defensa
- Transporte
- Finanzas
- Empleo
- Energía

## Metodología PDCA

ISO 42001 sigue el ciclo **Plan-Do-Check-Act**:

### Plan (Planificar)
- Definir alcance del AIMS
- Identificar controles necesarios
- Evaluar implicaciones éticas
- Establecer objetivos

### Do (Hacer)
- Implementar políticas de gobernanza
- Ejecutar controles definidos
- Asegurar prácticas responsables
- Capacitar personal

### Check (Verificar)
- Monitorear performance de IA
- Verificar cumplimiento regulatorio
- Realizar auditorías internas
- Medir efectividad de controles

### Act (Actuar)
- Refinar procesos basado en resultados
- Implementar acciones correctivas
- Adaptar a nuevos riesgos
- Mejorar continuamente

## Proceso de Certificación

### Fases de Auditoría

#### Fase 1: Definición del Alcance
- Identificar sistemas de IA en scope
- Determinar límites del AIMS
- Confirmar recursos disponibles

#### Fase 2: Evaluación de Riesgos y Definición de Controles
- Realizar evaluación de riesgos de IA
- Seleccionar controles del Anexo A
- Documentar Statement of Applicability

#### Fase 3: Revisión Documental
- Revisar políticas y procedimientos
- Verificar documentación del AIMS
- Identificar gaps

#### Fase 4: Auditoría Operacional
- Confirmar implementación de controles
- Entrevistar personal
- Revisar evidencia

#### Fase 5: Verificación de Acciones Correctivas
- Verificar cierre de hallazgos
- Confirmar remediación

#### Fase 6: Emisión de Certificación
- Válida por 3 años
- Auditorías de vigilancia anuales
- Recertificación al tercer año

## Beneficios de Implementación

### Confianza y Transparencia
- Sistemas de IA explicables y auditables
- Libre de sesgos verificable
- Mayor confianza de usuarios

### Alineamiento Regulatorio
- Cumplimiento con EU AI Act
- Alineación con DS 115-2025-PCM
- Preparación para futuras regulaciones

### Seguridad Mejorada
- Protección contra amenazas cibernéticas
- Prevención de mal uso de IA
- Controles de acceso robustos

### Ventaja Competitiva
- Demostrar liderazgo en IA responsable
- Diferenciación en el mercado
- Mayor confianza de clientes e inversores

### Resiliencia Operativa
- Detección temprana de problemas
- Mitigación proactiva de riesgos
- Continuidad de operaciones

## Integración con Otros Estándares

### ISO/IEC 27001 (Seguridad de la Información)
- AIMS se integra con ISMS existente
- Controles de seguridad compartidos
- Gestión de riesgos alineada

### ISO/IEC 27701 (Privacidad)
- Protección de datos personales
- Privacy by design en IA
- Cumplimiento GDPR/LPDP

### ISO/IEC 23894 (Gestión de Riesgos de IA)
- Framework de riesgos específico para IA
- Complementa ISO 42001
- Metodología de evaluación

### NIST AI RMF
- Framework de riesgo de IA de NIST
- Alineación con estándares US
- Categorías de riesgo similares

### OECD AI Principles
- Principios éticos de IA
- Adopción internacional
- Base para regulaciones

## Relevancia para DS 115-2025-PCM

### Alineamiento
ISO 42001 ayuda a cumplir con DS 115-2025-PCM:
- Gestión de riesgos de IA
- Documentación de sistemas
- Supervisión humana
- Transparencia algorítmica
- Auditorías periódicas

### Adopción Recomendada
El reglamento peruano recomienda adoptar estándares internacionales, incluyendo ISO 42001.

### Certificación como Evidencia
Una certificación ISO 42001 puede servir como evidencia de cumplimiento ante reguladores.

## 6 Pasos Clave hacia la Certificación ISO 42001

### Paso 1: Obtener Buy-in de Stakeholders
- Asegurar apoyo de alta dirección (requisito de Cláusula 5)
- Involucrar áreas clave: Legal, IT, Riesgos, C-level
- Designar un responsable o equipo de compliance
- Establecer gobernanza del proyecto de certificación

### Paso 2: Evaluación de Riesgos y Gap Analysis
Realizar evaluación integral cubriendo:
- **Implicaciones éticas** de los sistemas de IA
- **Seguridad e integridad de datos**
- **Transparencia algorítmica**
- Comparar prácticas actuales vs. requisitos ISO 42001
- Identificar brechas y desarrollar roadmap de cumplimiento

### Paso 3: Desarrollar Políticas, Objetivos y Controles
Construir el Sistema de Gestión de IA (AIMS):
- Política de IA documentada y aprobada
- Procesos de gestión de datos
- Framework de protección y gobernanza de datos
- Guías de implementación ética de IA
- Políticas de accountability y supervisión
- Implementar modelo PDCA para mejora continua

### Paso 4: Establecer Monitoreo y Documentación
Implementar procedimientos continuos para:
- Gestión de riesgos
- Workflows de diseño y testing de IA
- Gobernanza de datos
- Logs de incidentes
- Usar herramientas de automatización para centralizar documentación

### Paso 5: Preparar para Auditoría Externa
- Realizar auditoría interna por personal independiente
- Verificar que controles alinean con cláusulas de ISO 42001
- Validar cumplimiento del AIMS
- Seleccionar organismo certificador acreditado
- Preparar evidencia y documentación

### Paso 6: Establecer Mantenimiento Post-Certificación
- Auditorías internas anuales obligatorias (Cláusula 5.16)
- Monitoreo de cambios regulatorios
- Actualización ante avances tecnológicos
- Respuesta a amenazas emergentes
- Recertificación cada 3 años

## Organismos Certificadores Acreditados

### Principales Certificadores Globales
| Organismo | Acreditación | Notas |
|-----------|--------------|-------|
| **BSI** | UKAS + RvA | Primer CB acreditado por UKAS |
| **Schellman** | ANAB | Primer CB acreditado por ANAB |
| **SGS** | ANAB + SAC | Presencia global |
| **DNV** | Múltiple | Ofrece training + certificación |
| **NSF** | Múltiple | Especializado en tech |

### Criterios de Selección
- Acreditación reconocida (UKAS, ANAB, RvA, SAC)
- Experiencia en sector específico
- Cobertura geográfica
- Oferta de pre-assessment
- Disponibilidad de training

### Pre-Assessment Recomendado
Antes de la auditoría formal:
- Identificar no conformidades potenciales
- Corregir gaps sin impacto en certificación
- Validar preparación
- Reducir riesgo de hallazgos mayores

## Implementación Práctica (Resumen)

### Fase 1: Preparación
- Gap Analysis vs. requisitos ISO 42001
- Inventario de sistemas de IA en scope
- Evaluación de madurez actual

### Fase 2: Diseño del AIMS
- Definir alcance y límites
- Establecer política de IA
- Diseñar estructura organizacional
- Seleccionar controles aplicables del Anexo A

### Fase 3: Implementación
- Desarrollar procedimientos
- Implementar controles
- Capacitar personal
- Documentar evidencia

### Fase 4: Operación y Mejora
- Ejecutar procesos
- Monitorear efectividad
- Gestionar incidentes
- Aplicar PDCA para mejora continua

### Fase 5: Certificación
- Seleccionar organismo certificador acreditado
- Realizar pre-assessment (recomendado)
- Completar auditoría externa
- Obtener certificación
- Mantener cumplimiento anual

## Fuentes y Referencias

### Estándar Oficial
- [ISO/IEC 42001:2023 - ISO](https://www.iso.org/standard/42001)
- ISO/IEC 42001:2023 Full Text (First Edition, December 2023)

### Estándares Relacionados Referenciados
- ISO/IEC 22989:2022 - AI Concepts and Terminology
- ISO/IEC 23894 - AI Risk Management Guidance
- ISO/IEC 5338 - AI System Life Cycle Process
- ISO/IEC 27001 - Information Security Management
- ISO/IEC 27701 - Privacy Information Management
- ISO/IEC 25059 - Quality Model for AI Systems
- ISO/IEC TR 24027 - Bias in AI Systems
- ISO/IEC TR 24029-1 - Robustness of Neural Networks
- ISO/IEC TR 24368 - Ethical and Societal Concerns
- NIST AI Risk Management Framework 1.0

### Guías de Implementación
- [KPMG - ISO/IEC 42001](https://kpmg.com/ch/en/insights/artificial-intelligence/iso-iec-42001.html)
- [AWS - AI Lifecycle Risk Management](https://aws.amazon.com/blogs/security/ai-lifecycle-risk-management-iso-iec-420012023-for-ai-governance/)
- [Microsoft - ISO 42001 Compliance](https://learn.microsoft.com/en-us/compliance/regulatory/offering-iso-42001)
- [CSA - 6 Key Steps to ISO 42001 Certification](https://cloudsecurityalliance.org/blog/2025/07/07/6-key-steps-to-iso-42001-certification-explained)
- [A-LIGN - Understanding ISO 42001](https://www.a-lign.com/articles/understanding-iso-42001)

### Organismos Certificadores
- [BSI - ISO 42001](https://www.bsigroup.com/en-US/products-and-services/standards/iso-42001-ai-management-system/)
- [Schellman - ISO 42001 Certification](https://www.schellman.com/services/ai-services/iso-42001)
- [SGS - ISO 42001 Certification](https://www.sgs.com/en-us/services/iso-iec-42001-certification-artificial-intelligence-ai-management-system)
- [DNV - ISO 42001 Certification](https://www.dnv.us/services/iso-42001---service/)
- [NSF - ISO 42001](https://www.nsf.org/management-systems/information-security/iso-iec-42001-artificial-intelligence-management-system)

### Acreditación
- [ANAB - ISO 42001 CBs](https://anab.ansi.org/accreditation/iso-iec-42001-artificial-intelligence-management-systems/)
